{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af61053",
   "metadata": {},
   "source": [
    "## Data Exploration and Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3d7784",
   "metadata": {},
   "source": [
    "## Emotion Recognition Dataset\n",
    "\n",
    "\n",
    "**Emotion Categories:**\n",
    "\n",
    "- Angry\n",
    "- Fear\n",
    "- Happy\n",
    "- Neutral\n",
    "- Sad\n",
    "- Surprise\n",
    "\n",
    "**Dataset Statistics:**\n",
    "\n",
    "- Total Images: 24,385 files\n",
    "- Number of Emotion Categories: 5\n",
    "- Class Distribution:\n",
    "  - Angry: 3,993 files\n",
    "  - Disgust: 436 files (Dropped from the dataset)\n",
    "  - Fear: 4,103 files\n",
    "  - Happy: 7,164 files\n",
    "  - Neutral: 4,982 files\n",
    "  - Sad: 4,938 files\n",
    "  - Surprise: 3,205 files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda1a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8f98e",
   "metadata": {},
   "source": [
    "def preprocess_image_data(directory, target_size=(64, 64)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for class_label in os.listdir(directory):\n",
    "        class_dir = os.path.join(directory, class_label)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for image_file in os.listdir(class_dir):\n",
    "                image_path = os.path.join(class_dir, image_file)\n",
    "                try:\n",
    "                    # Open and resize the image\n",
    "                    image = Image.open(image_path).resize(target_size)\n",
    "                    images.append(np.array(image))\n",
    "                    labels.append(class_label)\n",
    "                except Exception as e:\n",
    "                    # Some images might be corrupted or not be images at all\n",
    "                    pass\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "789b8fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_data(directory, target_size=(64, 64), skip_folders=None):\n",
    "    if skip_folders is None:\n",
    "        skip_folders = []  # Default to an empty list if skip_folders is not provided\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    for class_label in os.listdir(directory):\n",
    "        if class_label in skip_folders:\n",
    "            continue  # Skip this folder\n",
    "        class_dir = os.path.join(directory, class_label)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for image_file in os.listdir(class_dir):\n",
    "                image_path = os.path.join(class_dir, image_file)\n",
    "                try:\n",
    "                    # Open and resize the image\n",
    "                    image = Image.open(image_path).resize(target_size)\n",
    "                    images.append(np.array(image))\n",
    "                    labels.append(class_label)\n",
    "                except Exception as e:\n",
    "                    # Some images might be corrupted or not be images at all\n",
    "                    pass\n",
    "    return images, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92f32759",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, y_train = preprocess_image_data(r'C:\\Users\\beast\\Documents\\Flatiron\\Gesture detection\\images\\train', skip_folders=['disgust'])\n",
    "x_test, y_test= preprocess_image_data(r'C:\\Users\\beast\\Documents\\Flatiron\\Gesture detection\\images\\validation', skip_folders=['disgust'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c25519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def undersample_data(x, y, desired_class_ratio=1.0, overrepresented_class=None):\n",
    "    # Combine x and y into a DataFrame\n",
    "    data_df = pd.DataFrame({'x_data': x, 'y_data': y})\n",
    "\n",
    "    # If the overrepresented class is not specified, find the class with the most samples\n",
    "    if overrepresented_class is None:\n",
    "        overrepresented_class = data_df['y_data'].value_counts().idxmax()\n",
    "\n",
    "    # Separate the overrepresented class and other classes\n",
    "    overrepresented_samples = data_df[data_df['y_data'] == overrepresented_class]\n",
    "    other_samples = data_df[data_df['y_data'] != overrepresented_class]\n",
    "\n",
    "    # Calculate the number of samples to keep for the overrepresented class\n",
    "    num_samples_to_keep = int(len(other_samples) * desired_class_ratio)\n",
    "\n",
    "    # Perform undersampling on the overrepresented class\n",
    "    undersampled_samples = resample(overrepresented_samples, n_samples=num_samples_to_keep, random_state=42)\n",
    "\n",
    "    # Combine the undersampled overrepresented class with the other classes\n",
    "    undersampled_data_df = pd.concat([undersampled_samples, other_samples])\n",
    "\n",
    "    # Extract x and y from the undersampled DataFrame\n",
    "    x_undersampled = undersampled_data_df['x_data'].values\n",
    "    y_undersampled = undersampled_data_df['y_data'].values\n",
    "\n",
    "    return x_undersampled, y_undersampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b83dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the images\n",
    "x_train = np.array(x_train) / 255.0\n",
    "x_test = np.array(x_test) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ff1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = preprocess_image_data(r'C:\\Users\\beast\\Documents\\Flatiron\\Gesture detection\\images\\train', skip_folders=['disgust'])\n",
    "x_test, y_test = preprocess_image_data(r'C:\\Users\\beast\\Documents\\Flatiron\\Gesture detection\\images\\validation', skip_folders=['disgust'])\n",
    "\n",
    "# Undersample the training data\n",
    "x_train_undersampled, y_train_undersampled = undersample_data(x_train, y_train, desired_class_ratio=1.0)\n",
    "\n",
    "# Undersample the test data\n",
    "x_test_undersampled, y_test_undersampled = undersample_data(x_test, y_test, desired_class_ratio=1.0)\n",
    "\n",
    "# Now, x_train_undersampled, y_train_undersampled, x_test_undersampled, and y_test_undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd582eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a98f81f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode class labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_undersampled)\n",
    "y_test_encoded = label_encoder.transform(y_test_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d6043a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m y_train_encoded \u001b[38;5;241m=\u001b[39m to_categorical(np\u001b[38;5;241m.\u001b[39marray(y_train_encoded))\n\u001b[0;32m      2\u001b[0m y_test_encoded \u001b[38;5;241m=\u001b[39m to_categorical(np\u001b[38;5;241m.\u001b[39marray(y_test_encoded))\n\u001b[1;32m----> 4\u001b[0m \u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m, y_train_encoded\u001b[38;5;241m.\u001b[39mshape, x_test\u001b[38;5;241m.\u001b[39mshape, y_test_encoded\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "y_train_encoded = to_categorical(np.array(y_train_encoded))\n",
    "y_test_encoded = to_categorical(np.array(y_test_encoded))\n",
    "\n",
    "x_train.shape, y_train_encoded.shape, x_test.shape, y_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967c61e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a CNN model with a custom evaluation metric\n",
    "def create_cnn_model(input_shape, num_classes, learning_rate=0.001, num_filters=32, dropout_rate=0.25, custom_metric='Accuracy'):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional Layer 1\n",
    "    model.add(Conv2D(num_filters, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Convolutional Layer 2\n",
    "    model.add(Conv2D(num_filters * 2, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Flatten the feature maps\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully Connected Layer 1\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))  # Dropout layer for regularization\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model with the specified learning rate and custom metric\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',  # Use categorical cross-entropy because of one hot encoding\n",
    "        metrics=[custom_metric]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "input_shape = (64,64, 1)  # Adjust the input shape according to your grayscale images\n",
    "num_classes = 6  # Number of emotion categories\n",
    "\n",
    "# Specify a custom evaluation metric (e.g., 'f1', 'precision', 'recall', etc.) or use the default 'Accuracy'\n",
    "custom_metric = 'accuracy'  # Change to a different metric if desired\n",
    "\n",
    "model = create_cnn_model(input_shape, num_classes, custom_metric=custom_metric)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d0991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d990838",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.argmax(model.predict(x_test), axis=1)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebbfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels = np.argmax(y_test_encoded, axis = 1)\n",
    "y_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d99125",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf = confusion_matrix(y_test_labels, predicted_labels)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cnf)\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_labels, predicted_labels), recall_score(y_test_labels, predicted_labels, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0056c43a",
   "metadata": {},
   "source": [
    "Increasing Complexity of themodel as it is underpreforming, also adding L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f2b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.regularizers import l2  # Import L2 regularization\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "def create_complex_cnn_model(input_shape, num_classes, learning_rate=0.001, num_filters=32, dropout_rate=0.25, custom_metric='accuracy'):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional Layer 1\n",
    "    model.add(Conv2D(num_filters, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 1))) \n",
    "\n",
    "    # Convolutional Layer 2\n",
    "    model.add(Conv2D(num_filters * 2, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 1))) \n",
    "\n",
    "    # Convolutional Layer 3\n",
    "    model.add(Conv2D(num_filters * 4, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "\n",
    "    # Convolutional Layer 4\n",
    "    model.add(Conv2D(num_filters * 4, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "\n",
    "    # Convolutional Layer 5\n",
    "    model.add(Conv2D(num_filters * 4, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 1))) \n",
    "\n",
    "    # Flatten the feature maps\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully Connected Layer 1 with L2 regularization\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Fully Connected Layer 2 with L2 regularization\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Fully Connected Layer 3 with L2 regularization\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model with the specified learning rate and custom metric\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[custom_metric]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "input_shape = (64, 64, 1)  # Adjust the input shape according to your grayscale images\n",
    "num_classes = 6  # Number of emotion categories\n",
    "\n",
    "# Specify a custom evaluation metric (e.g., 'f1', 'precision', 'recall', etc.) or use the default 'accuracy'\n",
    "custom_metric = 'accuracy'  # Change to a different metric if desired\n",
    "\n",
    "modelacc = create_complex_cnn_model(input_shape, num_classes, custom_metric=custom_metric)\n",
    "modelacc.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we are sure that our data is in a suitable format, and our model has been expanded, i will run again\n",
    "modelacc.fit(x_train, y_train_encoded, validation_data=(x_test, y_test_encoded))\n",
    "#predict and evaluate\n",
    "predicted_labels2 = np.argmax(modelacc.predict(x_test), axis=1)\n",
    "cnf = confusion_matrix(y_test_labels, predicted_labels2)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cnf)b\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f798cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_labels, predicted_labels2), recall_score(y_test_labels, predicted_labels2, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9070f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aaa208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bbab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.regularizers import l2  # Import L2 regularization\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "def create_complex_cnn_model(input_shape, num_classes, learning_rate=0.001, num_filters=32, dropout_rate=0.25, custom_metric='accuracy'):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional Layer 1\n",
    "    model.add(Conv2D(num_filters, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 1))) \n",
    "\n",
    "    # Convolutional Layer 2\n",
    "    model.add(Conv2D(num_filters * 2, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 1))) \n",
    "\n",
    "    # Convolutional Layer 3\n",
    "    model.add(Conv2D(num_filters * 4, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "\n",
    "    # Convolutional Layer 4\n",
    "    model.add(Conv2D(num_filters * 4, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "\n",
    "    # Convolutional Layer 5\n",
    "    model.add(Conv2D(num_filters * 4, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 1))) \n",
    "\n",
    "    # Flatten the feature maps\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully Connected Layer 1 with L2 regularization\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Fully Connected Layer 2 with L2 regularization\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Fully Connected Layer 3 with L2 regularization\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model with the specified learning rate and custom metric\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[custom_metric]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "input_shape = (64, 64, 1)  # Adjust the input shape according to your grayscale images\n",
    "num_classes = 6  # Number of emotion categories\n",
    "\n",
    "# Specify a custom evaluation metric (e.g., 'f1', 'precision', 'recall', etc.) or use the default 'accuracy'\n",
    "custom_metric = 'f1'  # Change to a different metric if desired\n",
    "\n",
    "modelf1 = create_complex_cnn_model(input_shape, num_classes, custom_metric=custom_metric)\n",
    "modelf1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8168b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we are sure that our data is in a suitable format, and our model has been expanded, i will run again\n",
    "modelf1.fit(x_train, y_train_encoded, validation_data=(x_test, y_test_encoded))\n",
    "#predict and evaluate\n",
    "predicted_labels2 = np.argmax(modelf1.predict(x_test), axis=1)\n",
    "cnf = confusion_matrix(y_test_labels, predicted_labels2)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cnf)\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4cabf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35b2a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2391b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb98871b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad8cd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a306374",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_wrapped_model = KerasClassifier(build_fn=create_cnn_model, epochs=10, batch_size=32, scoring='accuracy')\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'num_filters': [16, 32, 64],\n",
    "    'epochs': [10, 15, 20]\n",
    "}\n",
    "# Create GridSearchCV with the specified scoring metric\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_result = grid.fit(x_data, y_data)\n",
    "\n",
    "# Access the best hyperparameters and results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a57ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Training Wheels",
   "language": "python",
   "name": "training_wheels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
